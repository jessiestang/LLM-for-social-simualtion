{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da7f4a85",
   "metadata": {},
   "source": [
    "## Run the LLM framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1765c4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all modules\n",
    "import os\n",
    "import json\n",
    "import importlib\n",
    "from model_construct_assistant.construction_agent import ModelConstructor\n",
    "from code_generator.coding_agent import CodingAgent\n",
    "from Validation_module.validator import ModelValidation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46772271",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "model_name = \"gpt-4o-mini\" # default model\n",
    "if not api_key:\n",
    "    raise ValueError(\"Please set the OPENAI_API_KEY environment variable.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f40edd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the model construction agent with the problem description\n",
    "# save problem description in a text file named \"Example prompting template.txt\" under the folder \"model_construct_assistant\"\n",
    "mc = ModelConstructor(model_name = model_name)\n",
    "conceptual_model = mc.model_construction_pipeline(\n",
    "    file_path=\"Example prompting template2.txt\", save_path=\"Conceptual Model.json\"\n",
    ")\n",
    "print(conceptual_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194639ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the code generator agent with the input conceptual model\n",
    "# write your sepcificaiton of the coding task under the file \"user_requirements.txt\" under the folder \"code_generator\"\n",
    "json_path = os.path.join (\"..\", \"model_construct_assistant\", \"Conceptual Model.json\")\n",
    "with open(\"user_requirements.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "            user_requirements = file.read() \n",
    "ca = CodingAgent(model_name = model_name)\n",
    "generated_code = ca.run_pipeline(json_path, user_requirements)\n",
    "print(generated_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b3e813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the validation module to validate the generated code\n",
    "# save your output under the folder \"output_plots\" under the folder \"code_generator\"\n",
    "image_path = r\"E:\\LLM_for_abm\\LLM-for-social-simualtion\\code_generator\\output_plots\"\n",
    "vali = ModelValidation(model_name=model_name)\n",
    "vali.run_pipeline(image_path, conceptual_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aaa (3.11.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
